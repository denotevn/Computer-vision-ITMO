{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import classification_report\n",
    "from PIL import Image\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "with open(\"/home/tuandinh/Desktop/Computer Vision ITMO/Week2/model_10k.json\") as f:\n",
    "    config = json.load(f)\n",
    "config = json.dumps(config)\n",
    "loaded_model = tf.keras.models.model_from_json(config)\n",
    "loaded_model.load_weights(\"/home/tuandinh/Desktop/Computer Vision ITMO/Week2/Model_10k_images.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " activation (Activation)     (None, 148, 148, 32)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 32)        9248      \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 72, 72, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 64)        18496     \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 34, 34, 64)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 18496)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                1183808   \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 64)                0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,212,513\n",
      "Trainable params: 1,212,513\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DIR = \"/home/tuandinh/Desktop/Computer Vision ITMO/Week2/train\"\n",
    "TEST_DIR = \"/home/tuandinh/Desktop/Computer Vision ITMO/Week2/test_dir\"\n",
    "if os.path.exists(TEST_DIR) == False:\n",
    "    os.makedirs(TEST_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chọn ngẫu nhiên 10 tệp ảnh mèo từ khoảng [10450, 10550)\n",
    "cat_files = [f for f in os.listdir(TRAIN_DIR) if f.startswith('cat.') and\n",
    "             int(f.split('.')[1]) >= 10450 and int(f.split('.')[1]) < 10550]\n",
    "\n",
    "# Chọn ngẫu nhiên 100 tệp ảnh chó từ khoảng [10450, 10550)\n",
    "dog_files = [f for f in os.listdir(TRAIN_DIR) if f.startswith('dog.') and\n",
    "             int(f.split('.')[1]) >= 10450 and int(f.split('.')[1]) < 10550]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create folder for dog and cat\n",
    "if os.path.exists(os.path.join(TEST_DIR,'cat')) == False:\n",
    "    os.makedirs(os.path.join(TEST_DIR,'cat'))\n",
    "if os.path.exists(os.path.join(TEST_DIR,'dog')) == False:\n",
    "    os.makedirs(os.path.join(TEST_DIR,'dog'))\n",
    "CAT = os.path.join(TEST_DIR,'cat')\n",
    "DOG = os.path.join(TEST_DIR,'dog')\n",
    "for file in cat_files:\n",
    "    shutil.copy(os.path.join(TRAIN_DIR, file), os.path.join(CAT,file))\n",
    "\n",
    "for file in dog_files:\n",
    "    shutil.copy(os.path.join(TRAIN_DIR, file), os.path.join(DOG,file))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "epochs = 30 # количество эпох (итераций)\n",
    "batch_size = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=200,\n",
    "    class_mode='binary',\n",
    "    shuffle=False) #Сохраняет последовательноcть файлов из папки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 90ms/step\n",
      "Predictions:\n",
      "[array([0.2842053], dtype=float32), array([0.03384573], dtype=float32), array([0.04696162], dtype=float32), array([0.4514355], dtype=float32), array([0.18981262], dtype=float32)]\n",
      "[array([0.], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32), array([0.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "imgs,labels=test_generator.next()\n",
    "array_imgs=np.transpose(np.asarray([tf.keras.utils.img_to_array(img) for img in imgs]),(0,2,1,3))\n",
    "predictions=loaded_model.predict(imgs)\n",
    "print(\"Predictions:\")\n",
    "print([x for x in predictions[:5]]) # выводим первые 3 предсказания\n",
    "rounded_pred=np.asarray([np.round(i) for i in predictions]) #  округляем\n",
    "print([np.round(x) for x in predictions[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = labels\n",
    "y_pred = rounded_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8600000000000001"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_true, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.83      0.91      0.87       100\n",
      "         1.0       0.90      0.81      0.85       100\n",
      "\n",
      "    accuracy                           0.86       200\n",
      "   macro avg       0.86      0.86      0.86       200\n",
      "weighted avg       0.86      0.86      0.86       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute evaluation metrics\n",
    "report = classification_report(labels, y_pred)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cat.10483.jpg']\n",
      "['dog.10483.jpg']\n"
     ]
    }
   ],
   "source": [
    "# cat.10483.jpg and dog.10483.jpg\n",
    "TEST_DIR = \"/home/tuandinh/Desktop/Computer Vision ITMO/Week2/test\"\n",
    "CAT_PATH_1 = os.path.join(TEST_DIR, 'cat')\n",
    "DOG_PATH_1 = os.path.join(TEST_DIR,'dog')\n",
    "\n",
    "if os.path.exists(TEST_DIR) == False:\n",
    "    os.makedirs(TEST_DIR)\n",
    "if os.path.exists(CAT_PATH_1) == False:\n",
    "    os.makedirs(CAT_PATH_1)\n",
    "if os.path.exists(DOG_PATH_1) == False:\n",
    "    os.makedirs(DOG_PATH_1)\n",
    "# Copy images to test_dir\n",
    "cat_file = [f for f in os.listdir(TRAIN_DIR) if f.startswith('cat.') and\n",
    "             int(f.split('.')[1]) == 10483]\n",
    "dog_file = [f for f in os.listdir(TRAIN_DIR) if f.startswith('dog.') and\n",
    "            int(f.split('.')[1]) == 10483]\n",
    "\n",
    "print(cat_file)\n",
    "print(dog_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in cat_file:\n",
    "    shutil.copy(os.path.join(TRAIN_DIR, file), os.path.join(CAT_PATH_1,file))\n",
    "\n",
    "for file in dog_file:\n",
    "    shutil.copy(os.path.join(TRAIN_DIR, file), os.path.join(CAT_PATH_1,file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    TEST_DIR,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=2,\n",
    "    class_mode='binary',\n",
    "    shuffle=False) #Сохраняет последовательноcть файлов из папки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 27ms/step\n",
      "Predictions:\n",
      "[array([0.2597945], dtype=float32), array([0.70030475], dtype=float32)]\n",
      "[array([0.], dtype=float32), array([1.], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "imgs,labels=test_generator.next()\n",
    "array_imgs=np.transpose(np.asarray([tf.keras.utils.img_to_array(img) for img in imgs]),(0,2,1,3))\n",
    "predictions=loaded_model.predict(imgs)\n",
    "print(\"Predictions:\")\n",
    "print([x for x in predictions[:5]]) # выводим первые 3 предсказания\n",
    "rounded_pred=np.asarray([np.round(i) for i in predictions]) #  округляем\n",
    "print([np.round(x) for x in predictions[:5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
